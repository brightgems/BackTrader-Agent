#!/usr/bin/env python3
"""æœ€ç»ˆä¿®å¤æµ‹è¯•è„šæœ¬"""

import sys
import os

print("=== æœ€ç»ˆä¿®å¤æµ‹è¯• ===")
print(f"Pythonç¼–ç : {sys.getdefaultencoding()}")

# é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv(override=True)

# æ£€æŸ¥å…³é”®é…ç½®
print("\n=== é…ç½®æ£€æŸ¥ ===")
print(f"APIç«¯ç‚¹: {os.getenv('OPENAI_BASE_URL')}")
print(f"æ¨¡å‹åç§°: {os.getenv('OPENAI_MODEL')}")
print(f"APIå¯†é’¥: {os.getenv('OPENAI_API_KEY')[:20]}...")

try:
    print("\n=== å¯¼å…¥æœåŠ¡ ===")
    from llm_advisory.services.openai_service import get_openai_service
    
    print("âœ… å¯¼å…¥æˆåŠŸ")
    
    print("\n=== æµ‹è¯•æœåŠ¡åˆå§‹åŒ– ===")
    service = get_openai_service()
    print("âœ… æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
    
    print("\n=== æµ‹è¯•ç®€å•çš„APIè°ƒç”¨ ===")
    try:
        # ä½¿ç”¨ç®€å•çš„è‹±æ–‡æµ‹è¯•é¿å…ç¼–ç é—®é¢˜
        response = service.create_chat_completion(
            messages=[{"role": "user", "content": "Hello"}],
            model="ERNIE-Bot-turbo",
            max_tokens=10
        )
        print("âœ… APIè°ƒç”¨æˆåŠŸï¼")
        print(f"å“åº”: {response.get('content', 'N/A')}")
        print("\nğŸ‰ å­—ç¬¦ç¼–ç é—®é¢˜å·²ä¿®å¤ï¼ç³»ç»Ÿå¯ä»¥æ­£å¸¸å·¥ä½œäº†ã€‚")
        
    except Exception as e:
        print(f"âŒ APIè°ƒç”¨å¤±è´¥: {e}")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        
        # æä¾›æ›¿ä»£æ–¹æ¡ˆ
        print(f"\nğŸ”§ å¦‚æœä»ç„¶æœ‰é—®é¢˜ï¼Œè¯·å°è¯•ä»¥ä¸‹æ–¹æ¡ˆï¼š")
        print(f"1. æ£€æŸ¥ç™¾åº¦åƒå¸†è´¦æˆ·çš„APIé…é¢å’Œæƒé™")
        print(f"2. éªŒè¯APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
        print(f"3. è”ç³»ç™¾åº¦åƒå¸†æŠ€æœ¯æ”¯æŒ")
        print(f"4. ä½¿ç”¨ç¦»çº¿OllamaæœåŠ¡ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")

except Exception as e:
    print(f"âŒ ç³»ç»Ÿé”™è¯¯: {e}")
    import traceback
    traceback.print_exc()

print("\n=== æµ‹è¯•å®Œæˆ ===")